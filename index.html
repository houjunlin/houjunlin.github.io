<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Jilan Xu</title>
  
  <meta name="author" content="Jilan Xu">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:65%;vertical-align:middle">
              <p style="text-align:center">
                <name>Junlin Hou</name>
		<br>
		 <a href="mailto:[deletethis] jilanxu18@fudan.edu.cn", style="color:grey">jilanxu18 at fudan dot edu dot cn</a>
		<br>
		<br>
              <p>I am a second year PhD student at Fudan University, advised by Professor Yuejie Zhang. My research focuses on multimodal machine learning, video understanding, semantic segmentation, and medical image analysis. I hope that someday medical AI agents would heal the world, make it a better place, for the entire human race.
              <p style="text-align:center">
                <a href="https://scholar.google.com/citations?user=mf2U64IAAAAJ&hl=en&oi=ao">Google Scholar</a> &nbsp/&nbsp
		            <a href="https://twitter.com/JazzzCharles">Twitter</a> &nbsp/&nbsp
                <a href="https://github.com/Jazzcharles"> GitHub </a> &nbsp/&nbsp
                <a href="https://www.zhihu.com/people/Jazz_charles">Zhihu</a>&nbsp
              </p>
            </td>
            <style>
              
            </style> 
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/nologo.jpg"><img style="width:70%;max-width:70%;border-radius:50%" alt="profile photo" src="images/nologo.jpg" class="img-circle" ></a>
            </td>
          </tr>
        </tbody></table>
	
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <heading>Research</heading>

          </td>
            </tr>
        </tbody></table>
        <style>
          img {
            border-radius: 15px;
          }
        </style>
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
         	   <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src="images/ovsegmentor.png" alt="ovsegmentor" width="160" height="100">
                </td>
                <td width="75%" valign="middle">
                  <a href="https://arxiv.org/abs/2301.09121">
                    <papertitle> Learning Open-vocabulary Semantic Segmentation Models From Natural Language Supervision </papertitle>
                  </a>
                  <br>
			                <b>Jilan Xu</b>, Junlin Hou, Yuejie Zhang, Rui Feng, Yi Wang, Yu Qiao, Weidi Xie
                  <br>
                  <em>CVPR</em> 2023 &nbsp 
                  <br>
                  <a href="https://arxiv.org/pdf/2301.09121.pdf">arXiv</a> / <a href="https://jazzcharles.github.io/OVSegmentor">project page</a> / <a href="https://github.com/Jazzcharles/OVSegmentor">code</a>
                  <p></p>
                  <p>Training open-vocabulary semantic segmentation models with image-text pairs only, which enables zero-transfer to various segmentation datasets. </p>
                </td>
              </tr>
		

              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src="images/cream.png" alt="cream" width="160" height="100">
                </td>
                <td width="75%" valign="middle">
                  <a href="https://arxiv.org/abs/2205.13922">
                    <papertitle> CREAM: Weakly supervised object localization via class re-activation mapping </papertitle>
                  </a>
                  <br>
			                <b>Jilan Xu</b>, Junlin Hou, Yuejie Zhang, Rui Feng, Rui-Wei Zhao, Tao Zhang, Xuequan Lu, Shang Gao
                  <br>
                  <em>CVPR</em> 2022 &nbsp 
                  <br>
                  <a href="https://arxiv.org/pdf/2205.13922.pdf">arXiv</a>
                  <p></p>
                  <p>A weakly-supervised object localization model that generates better CAMs via soft-clustering algorithms. </p>
                </td>
              </tr>

              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src="images/cmcv2.png" alt="cmcv2" width="160" height="100">
                </td>
                <td width="75%" valign="middle">
                  <a href="https://arxiv.org/abs/2211.14557">
                    <papertitle> CMC_v2: Towards More Accurate COVID-19 Detection with Discriminative Video Priors </papertitle>
                  </a>
                  <br>
                      Junlin Hou, <b>Jilan Xu</b>, Nan Zhang, Yi Wang, Yuejie Zhang, Xiaobo Zhang, Rui Feng
                  <br>
                  <em>ECCV</em> 2022 AIMIA Workshop &nbsp 
                  <br>
                  <a href="https://arxiv.org/pdf/2211.14557.pdf">arXiv</a> / <a href="https://github.com/houjunlin/Team-FDVTS-COVID-Solution">code</a>
                  <p></p>
                  <p>A Transformer-based model with contrastive representation enhancement. Winner of the 2nd COVID-19 Detection in ECCV 2022. </p>
                </td>
              </tr>

              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src="images/internvideo.png" alt="internvideo" width="160" height="100">
                </td>
                <td width="75%" valign="middle">
                  <a href="https://arxiv.org/abs/2212.03191">
                    <papertitle> InternVideo: General Video Foundation Models via Generative and Discriminative Learning </papertitle>
                  </a>
                  <br>
                    Yi Wang, Kunchang Li, Yizhuo Li, Yinan He, Bingkun Huang, Zhiyu Zhao, Hongjie Zhang, <b>Jilan Xu</b>, Yi Liu, Zun Wang, Sen Xing, Guo Chen, Junting Pan, Jiashuo Yu, Yali Wang, Limin Wang, Yu Qiao
                  <br>
                  <em>Tech report</em> 2022 &nbsp 
                  <br>
                  <a href="https://arxiv.org/pdf/2212.03191.pdf">arxiv</a> / <a href="https://github.com/OpenGVLab/InternVideo">code</a>
                  <p></p>
                  <p>A fundation model for video / video-text understanding, achieving SOTA over 30 benchmark datasets. </p>
                </td>
              </tr>


              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src="images/tccnet.png" alt="tccnet" width="160" height="100">
                </td>
                <td width="75%" valign="middle">
                  <a href="https://www.ijcai.org/proceedings/2022/0155.pdf">
                    <papertitle> TCCNet: Temporally Consistent Context-Free Network for Semi-supervised Video Polyp Segmentation </papertitle>
                  </a>
                  <br>
                    Xiaotong Li, <b>Jilan Xu</b>, Yuejie Zhang, Rui Feng, Rui-Wei Zhao, Tao Zhang, Xuequan Lu, Shang Gao
                  <br>
                  <em>IJCAI</em> 2022, Oral &nbsp 
                  <br>
                  <a href="https://www.ijcai.org/proceedings/2022/0155.pdf">paper</a>
                  <p></p>
                  <p>Co-training a model for semi-supervised video polyp segmentation, achieving comparable results using only 15% labeled data.</p>
                </td>
              </tr>

              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src="images/cmcv1.png" alt="cmcv1" width="160" height="100">
                </td>
                <td width="75%" valign="middle">
                  <a href="https://openaccess.thecvf.com/content/ICCV2021W/MIA-COV19D/papers/Hou_CMC-COV19D_Contrastive_Mixup_Classification_for_COVID-19_Diagnosis_ICCVW_2021_paper.pdf">
                    <papertitle> CMC-COV19D: Contrastive Mixup Classification for COVID-19 Diagnosis </papertitle>
                  </a>
                  <br>
                    Junlin Hou*, <b>Jilan Xu*</b>, Rui Feng, Yuejie Zhang, Fei Shan, Weiya Shi
                  <br>
                  <em>ICCV</em> 2021, AIMIA Workshop. &nbsp 
                  <br>
                  <a href="https://openaccess.thecvf.com/content/ICCV2021W/MIA-COV19D/papers/Hou_CMC-COV19D_Contrastive_Mixup_Classification_for_COVID-19_Diagnosis_ICCVW_2021_paper.pdf">paper</a> / <a href="https://github.com/houjunlin/Team-FDVTS-COVID-Solution">code</a>
                  <p></p>
                  <p>A ResNest-50 model combined with contrastive mixup technique for 3D COVID-19 CT image classification. Winner of the 1st COVID-19 detection challenge.</p>
                </td>
              </tr> 

              
              
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src="images/drl.png" alt="drl" width="160" height="100">
                </td>
                <td width="75%" valign="middle">
                  <a href="https://ieeexplore.ieee.org/document/9313159/#:~:text=Data-Efficient%20Histopathology%20Image%20Analysis%20with%20Deformation%20Representation%20Learning,are%20often%20expensive%20and%20laborious%20in%20realworld%20scenarios.">
                    <papertitle> Data-Efficient Histopathology Image Analysis with Deformation Representation Learning </papertitle>
                  </a>
                  <br>
                    <b>Jilan Xu</b>, Junlin Hou, Yuejie Zhang, Rui Feng, Chunyang Ruan, Tao Zhang, Weiguo Fan
                  <br>
                  <em>BIBM</em> 2020, Oral &nbsp 
                  <br>
                  <a href="https://ieeexplore.ieee.org/document/9313159/#:~:text=Data-Efficient%20Histopathology%20Image%20Analysis%20with%20Deformation%20Representation%20Learning,are%20often%20expensive%20and%20laborious%20in%20realworld%20scenarios.">paper</a>
                  <p></p>
                  <p>Introducing a self-supervised deformation representation learning technique for histopathology image analysis.</p>
                </td>
              </tr>

        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Awards & Honors</heading>
              <p>
                  <ul>
                    <li>Winner of the 1st & 2nd COVID-19 Detection Challenge @ ICCV 2021 & ECCV 2022</li>
                    <li>Winner of the 1st COVID-19 Severity Detection Challenge @ ECCV 2022</li>
                    <li>VenusTech Enterprise Scholarship</li>
                  </ul>
              </p>
            </td>
          </tr> 
        </tbody></table>


        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Working Experience</heading>
              <p>
                  <ul>
                    <li>Research intern @ Shanghai AI Laboratory, supervised by Dr. Yi Wang and Prof. Yu Qiao.</li>
                    <li>Research intern @ Bell AI Lab, Shanghai, supervised by Dr. Chenhui Ye.</li>
                    <li>Google Winter AI Camp. Our team won the best presentation award !!!</li>
                    <li>SWE intern @ Morgan Stanley Technology, supervised by Ray Zhou.</li>
                  </ul>
              </p>
            </td>
          </tr> 
        </tbody></table>



        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Service</heading>
              <p>
                <strong> Reviewer </strong>: CVPR23, ICCV23, NeurIPS22, NeuroComputing
              </p>
              <p>
                <strong> TA </strong>: Data Structure, Theory of Computation
              </p>
            </td>
          </tr> 
        </tbody></table>

        <div id="topbtn-md">
          <a href="#" type="button" class="btn btn-light">
              <span class="lang-en">Top</span>
          </a>
        </div>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                 <a href="https://jonbarron.info/">This</a> guy is good at website design.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
